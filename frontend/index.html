<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8" />
    <title>AIA - Tutor de Voz (Barge-in Real)</title>
    <style>
        body {
            font-family: 'Segoe UI', sans-serif;
            background: #f4f5f7;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 12px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
            text-align: center;
            max-width: 600px;
            width: 100%;
        }
        button {
            font-size: 18px;
            padding: 14px 32px;
            border-radius: 50px;
            border: none;
            cursor: pointer;
            background: #0056ff;
            color: white;
            margin-top: 20px;
        }
        button:hover { background: #0044cc; }
        #console {
            margin-top: 20px;
            height: 250px;
            background: #1e1e1e;
            color: #0f0;
            padding: 10px;
            border-radius: 8px;
            overflow-y: scroll;
            text-align: left;
            font-family: monospace;
            font-size: 12px;
        }
        .status-dot {
            height: 10px; width: 10px; 
            background-color: #bbb; 
            border-radius: 50%; 
            display: inline-block;
        }
    </style>
</head>
<body>

<div class="container">
    <h2>AIA - Tutor de Voz</h2>
    <p>Fale para interromper. O sistema limpar√° a fila de √°udio instantaneamente.</p>
    
    <div id="status-text">Status: Parado</div>
    <button id="startBtn">üìû Iniciar Conversa</button>
    <div id="console"></div>
</div>

<script>
// ==========================================
// 1. CONFIGURA√á√ÉO E VARI√ÅVEIS
// ==========================================
const AIA_TOKEN = localStorage.getItem("AIA_TOKEN");
if (!AIA_TOKEN) window.location.href = "login.html";

let ws = null;
let audioContext = null;
let processor = null;
let input = null;
let isRecording = false;

// --- GERENCIADOR DE FILA DE √ÅUDIO ---
let nextStartTime = 0; 
let scheduledSources = []; // Lista de todos os pedacinhos na fila

function log(msg) {
    const box = document.getElementById("console");
    const ts = new Date().toLocaleTimeString();
    box.innerHTML += `<div><span style="color:#666">[${ts}]</span> ${msg}</div>`;
    box.scrollTop = box.scrollHeight;
}

// ==========================================
// 2. CONTROLE PRINCIPAL
// ==========================================
const btn = document.getElementById("startBtn");

btn.onclick = async () => {
    if (!isRecording) await startConversation();
    else stopConversation();
};

async function startConversation() {
    document.getElementById("status-text").innerText = "Conectando...";
    audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    
    ws = new WebSocket(`ws://localhost:8000/ws?token=${AIA_TOKEN}`);
    ws.binaryType = "arraybuffer";

    ws.onopen = () => {
        log("‚úÖ Conectado.");
        btn.innerText = "üü• Parar";
        btn.style.background = "#dc3545";
        startMicPCM();
        isRecording = true;
    };

    ws.onmessage = (event) => {
        // A. √ÅUDIO (PCM)
        if (event.data instanceof ArrayBuffer) {
            playPCM16(event.data);
        } 
        // B. COMANDOS (JSON)
        else {
            try {
                const msg = JSON.parse(event.data);
                if (msg.type === "interrupt") {
                    log("üõë Interrup√ß√£o! Limpando √°udio...");
                    clearAudioQueue(); // <--- A M√ÅGICA ACONTECE AQUI
                } else if (msg.type === "transcript") {
                    log("üìù " + msg.text);
                }
            } catch(e) {}
        }
    };

    ws.onclose = () => stopConversation();
}

function stopConversation() {
    clearAudioQueue();
    if (processor) { processor.disconnect(); processor = null; }
    if (input) { input.disconnect(); input = null; }
    if (ws) { ws.close(); ws = null; }
    if (audioContext) { audioContext.close(); audioContext = null; }
    
    isRecording = false;
    btn.innerText = "üìû Iniciar Conversa";
    btn.style.background = "#0056ff";
    document.getElementById("status-text").innerText = "Status: Parado";
}

// ==========================================
// 3. GERENCIAMENTO DE √ÅUDIO (CORRE√á√ÉO DE OVERLAP)
// ==========================================

function clearAudioQueue() {
    // 1. Para CADA pedacinho que estava agendado
    scheduledSources.forEach(source => {
        try { source.stop(); } catch(e) {}
    });
    // 2. Limpa a lista
    scheduledSources = [];
    
    // 3. Reseta o rel√≥gio para AGORA (para o novo √°udio n√£o sair com delay)
    if (audioContext) {
        nextStartTime = audioContext.currentTime; 
    }
}

function playPCM16(arrayBuffer) {
    if (!audioContext) return;

    // Convers√£o Int16 -> Float32
    const dataView = new DataView(arrayBuffer);
    const float32 = new Float32Array(arrayBuffer.byteLength / 2);
    for (let i = 0; i < float32.length; i++) {
        const int16 = dataView.getInt16(i * 2, true);
        float32[i] = int16 / 32768.0;
    }

    const buffer = audioContext.createBuffer(1, float32.length, 24000);
    buffer.getChannelData(0).set(float32);

    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    source.connect(audioContext.destination);

    // Sincronia
    const currentTime = audioContext.currentTime;
    if (nextStartTime < currentTime) nextStartTime = currentTime;
    
    source.start(nextStartTime);
    nextStartTime += buffer.duration;

    // ADICIONA √Ä LISTA DE CONTROLE
    scheduledSources.push(source);

    // REMOVE DA LISTA QUANDO TERMINAR SOZINHO
    source.onended = () => {
        scheduledSources = scheduledSources.filter(s => s !== source);
    };
}

// ==========================================
// 4. MICROFONE (PCM 24kHz)
// ==========================================
async function startMicPCM() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: { channelCount: 1, echoCancellation: true, noiseSuppression: true, sampleRate: 24000 } 
        });
        input = audioContext.createMediaStreamSource(stream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);

        processor.onaudioprocess = (e) => {
            if (!ws || ws.readyState !== WebSocket.OPEN) return;
            const inputData = e.inputBuffer.getChannelData(0);
            const buffer = new ArrayBuffer(inputData.length * 2);
            const view = new DataView(buffer);
            for (let i = 0; i < inputData.length; i++) {
                let s = Math.max(-1, Math.min(1, inputData[i]));
                view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            ws.send(buffer);
        };
        input.connect(processor);
        processor.connect(audioContext.destination);
    } catch (e) { alert("Erro Mic: " + e); }
}
</script>
</body>
</html>